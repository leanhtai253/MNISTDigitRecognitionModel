{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb566a38",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e21231a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd2619fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "129b638f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ce397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4977c25f",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df023c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN requires 3-dimension input so we have to reshape the matrix to shape\n",
    "#(60000, 28, 28, 1)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "INPUT_SHAPE = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f033d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert class vectors to categorical data matrix (binary class matrices)\n",
    "NR_CLASSES = 10 #from 0 to 9\n",
    "y_train = keras.utils.to_categorical(y_train, NR_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NR_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ac12483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for easy computations during the process\n",
    "#we should convert the datatype from uint8 to float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#Rescaling\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f30be46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bc83f",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3d944c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A CNN model generally consists of convolutional and pooling layers\n",
    "#It works better for data that are represented as grid structures\n",
    "#We add dropout layers to deactivate some neurons and reduce overfitting\n",
    "BATCH_SIZE = 128\n",
    "NR_EPOCHS = 10\n",
    "#Initialize our neural networks\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu',\n",
    "                input_shape=INPUT_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NR_CLASSES, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d8e2e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "loss_function = keras.losses.categorical_crossentropy\n",
    "#Optimizer\n",
    "optimization = keras.optimizers.Adadelta()\n",
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec49b4",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac0b92ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 20s 44ms/step - loss: 0.4180 - accuracy: 0.8672 - val_loss: 0.0649 - val_accuracy: 0.9782\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.1220 - accuracy: 0.9675 - val_loss: 0.0485 - val_accuracy: 0.9855\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0857 - accuracy: 0.9779 - val_loss: 0.0423 - val_accuracy: 0.9870\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 22s 48ms/step - loss: 0.0692 - accuracy: 0.9823 - val_loss: 0.0375 - val_accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0567 - accuracy: 0.9850 - val_loss: 0.0300 - val_accuracy: 0.9910\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0488 - accuracy: 0.9868 - val_loss: 0.0307 - val_accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 23s 48ms/step - loss: 0.0433 - accuracy: 0.9886 - val_loss: 0.0297 - val_accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0370 - accuracy: 0.9900 - val_loss: 0.0327 - val_accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 23s 49ms/step - loss: 0.0317 - accuracy: 0.9913 - val_loss: 0.0330 - val_accuracy: 0.9914\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 24s 51ms/step - loss: 0.0313 - accuracy: 0.9916 - val_loss: 0.0351 - val_accuracy: 0.9908\n",
      "Model successfully trained\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=NR_EPOCHS,\n",
    "                validation_data=(x_test, y_test), verbose=1)\n",
    "print(\"Model successfully trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927158ee",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdad93a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.04\n",
      "Test accuracy: 99.08%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]:.2f}')\n",
    "print(f'Test accuracy: {score[1]:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42addb14",
   "metadata": {},
   "source": [
    "# Test with test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "62eb9410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABAElEQVR4nO2Vyw2DMAyG3ap3RoAVmMCBrXICbwIbMEEEmzBCmMA9VFR9EGLTqhIV3xET/vjHjxMzM/yQ8y/FDsEgRAREtEnwJC2aWWAYhqfnzjmVoChDIroLISI45+5C2kwvsRemaYK+76HrOkiS5CmGiG8ZR2EB4zgGY0VRcF3Xks8wM7PI0jRNgzFEVCW4j7b4CLH5C3jv2RjD3nvxmWiVhphbJc/zt+pdY5NgWZYAcCuYqqp0hzUWWmvZGMPWWrX9KksfJ03TNKttEmNV8HWkqe1bIDi8iQjatoUsy8TNLbnQ6rbQDObZiej22Pz3F5DMVPE+/Bb/P0sPwf0LXgGAJwNqzP5nHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=28x28 at 0x1A7D1A76D30>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('test_img.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18309d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert image to grayscale\n",
    "bw = img.convert('L')\n",
    "#Convert to array\n",
    "img_array = np.invert(bw)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "468d7920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img = img_array.reshape((1,28,28,1))\n",
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87f2d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict([test_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fbb78c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted digit is: 2\n",
      "With 100.00% confidence\n"
     ]
    }
   ],
   "source": [
    "print('The predicted digit is:', np.argmax(res[0]))\n",
    "print(f'With {max(res[0]):.2%} confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3998e9a",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2e31e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Adminned\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From D:\\Adminned\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: HandwrittenDigitRecognizer.pb\\assets\n"
     ]
    }
   ],
   "source": [
    "#model.save('HandwrittenDigitRecognizer.h5')\n",
    "#model.save('HandwrittenDigitRecognizer.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c43d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
